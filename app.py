import streamlit as st
import google.generativeai as genai
import json
import os
import glob

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
CHATS_DIR = "my_chats"
if not os.path.exists(CHATS_DIR):
    os.makedirs(CHATS_DIR)

# ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
def get_chat_files():
    files = glob.glob(os.path.join(CHATS_DIR, "*.json"))
    return [os.path.basename(f).replace(".json", "") for f in files]

def save_chat(chat_name, messages):
    file_path = os.path.join(CHATS_DIR, f"{chat_name}.json")
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=4)

def load_chat(chat_name):
    file_path = os.path.join(CHATS_DIR, f"{chat_name}.json")
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù„ØªÙ†Ø³ÙŠÙ‚ Gemini Ø§Ù„Ø±Ø³Ù…ÙŠ (Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© KeyError)
def format_for_gemini(messages):
    formatted = []
    for m in messages:
        role = "user" if m["role"] == "user" else "model"
        formatted.append({"role": role, "parts": [{"text": m["content"]}]})
    return formatted

st.set_page_config(page_title="Gemini Pro Studio", layout="wide")
st.title("ğŸš€ Gemini Advanced Interface")

with st.sidebar:
    st.header("ğŸ”‘ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    api_key = st.text_input("API Key:", type="password")
    
    st.divider()
    st.header("ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª")
    existing_chats = get_chat_files()
    selected_chat = st.selectbox("Ø§Ø®ØªØ± Ù…Ø­Ø§Ø¯Ø«Ø©:", [""] + existing_chats)
    
    if api_key:
        try:
            genai.configure(api_key=api_key)
            if "models_list" not in st.session_state:
                st.session_state.models_list = [m.name.replace('models/', '') for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            model_choice = st.selectbox("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", st.session_state.models_list)
        except:
            st.error("ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù€ API Key")

# Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
if api_key and selected_chat:
    model = genai.GenerativeModel(model_name=f"models/{model_choice}")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    if "messages" not in st.session_state or st.session_state.get("last_chat") != selected_chat:
        st.session_state.messages = load_chat(selected_chat)
        st.session_state.last_chat = selected_chat
        st.session_state.view_limit = 10 # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¹Ø±Ø¶ Ø¢Ø®Ø± 10

    # Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯
    if len(st.session_state.messages) > st.session_state.view_limit:
        if st.button("ğŸ”½ ØªØ­Ù…ÙŠÙ„ Ø±Ø³Ø§Ø¦Ù„ Ø£Ù‚Ø¯Ù…"):
            st.session_state.view_limit += 10
            st.rerun()

    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù„ÙŠÙ…ÙŠØª Ø§Ù„Ù…Ø®ØªØ§Ø±)
    display_msgs = st.session_state.messages[-st.session_state.view_limit:]
    for m in display_msgs:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
    if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..."):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # ØªØ­Ø³ÙŠÙ†: Ø¥Ø±Ø³Ø§Ù„ Ø¢Ø®Ø± 10 Ø±Ø³Ø§Ø¦Ù„ ÙÙ‚Ø· Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ 429 Ùˆ 404
        # Ø§Ù„Ù€ history ÙŠØ­ØªØ§Ø¬ Ù„ØªÙ†Ø³ÙŠÙ‚ 'parts'
        history_to_send = format_for_gemini(st.session_state.messages[-11:-1])
        
        chat = model.start_chat(history=history_to_send)
        
        try:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                response = chat.send_message(prompt)
            
            with st.chat_message("assistant"):
                st.markdown(response.text)
            
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            save_chat(selected_chat, st.session_state.messages)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ (Ø¥ØµÙ„Ø§Ø­ KeyError)
            formatted_history = format_for_gemini(st.session_state.messages)
            tokens = model.count_tokens(formatted_history).total_tokens
            st.sidebar.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙˆÙƒÙ†Ø² ÙÙŠ Ø§Ù„Ù…Ù„Ù", tokens)
            
        except Exception as e:
            st.error(f"Ø®Ø·Ø£: {e}")

elif not selected_chat:
    st.info("Ø§Ø®ØªØ± Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡.")